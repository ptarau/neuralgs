# neuralgs

## Experiments with neural networks learning theorem proving and complex recursion-heavy algorithms

### tlin_nlp.py contains code for training a seq2seq network to  find the proof term  associated to a fomula in implicational linear logic

The file training.txt contains a training dataset for neural networks trying to emulate theorem provers. It contains lines of theorem:proofterm pairs like the following:

00000AABB00CC00DD00EEFF:1A0000A1B0B1CC1DD1EE1FF
000AA00BB00CC00DD00EEFF:1A00000A1BB1CC1DD1EE1FF

with trees converted to unambiguous prefix notation where

0=lollipop on the left (theorems), application on the right (in proof terms)
1=lambda
A,B,C,... = variables (on the left standing for types, on the right for lambda variables)

### cats_rnn.py contains code for learning the successor function in a tree-based arithmetic system

Its data is generated by the catnum.py program, agorithmically.

To run these, install keras + tensorflow, then do:

```
python3 -i tlin_rnn.py
>>> run()
```
and

```
python3 -i cats_rnn.py
>>> run()
```
