# neuralgs

## Experiments with neural networks learning theorem proving and complex recursion-heavy algorithms. 

The files ```cs2cs.py``` and ```s2s.py``` contain two different algorithms for seq2seq learning one character at a time, encapsulated as Python3 classes dependent on the same convention about data files and models, using ```tensorflow 2.x``` via the ```keras``` interface.

Training data files are in the folder ```data``` and generated models go to the folder ```models```.

### Learning to prove theorems in the implicational fragment of linear propositional intuitionistic logic.

We use two  seq2seq algorithms to  find the proof term  associated to a fomula in implicational linear logic.


The file ```data/tlin.txt``` contains a training dataset for neural networks trying to emulate theorem provers. It contains lines of "theorem:proofterm" pairs like the following:

00000AABB00CC00DD00EEFF:1A0000A1B0B1CC1DD1EE1FF
000AA00BB00CC00DD00EEFF:1A00000A1BB1CC1DD1EE1FF

with trees converted to unambiguous prefix notation where

0=lollipop on the left (theorems), application on the right (in proof terms)
1=lambda
A,B,C,... = variables (on the left standing for types, on the right for lambda variables)



The file ```data/full_tlin.txt``` contains theorems and non-theorems of the same logic, absence of a proof term being marked with the symbol ```?```. Ohthervise the format is the same.


### learning a nested recursive successor algorithm working on a tree-representation of natural numbers.
 
The file ```data/cats.txt``` contains data for learning the successor function in a tree-based arithmetic system. It has been generated by the catnum.py program, agorithmically.

### Running the programs

To run these, install tensorflow 2.x, then do:

```
python3 -i cs2cs/py
>>> run()
```
and

```
python3 -i s2s.py
>>> run()
```

Two research papers, in PDF, in folder ```docs``` explain the algorithms used to generate the training data files.

